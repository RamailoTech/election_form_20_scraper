{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_excel_files(folder_path):\n",
    "    excel_files = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.xlsx'):\n",
    "            excel_files.append(pd.read_excel(\n",
    "                os.path.join(folder_path, filename)))\n",
    "    return excel_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if column names are the same\n",
    "def check_column_lengths(df_list):\n",
    "    column_lengths = [set(df.columns) for df in df_list]\n",
    "    return column_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Function to merge DataFrames with the same number of columns\n",
    "\n",
    "\n",
    "def concatenate_dfs(df_list):\n",
    "    # Group DataFrames by number of columns\n",
    "    grouped_dfs = defaultdict(list)\n",
    "    for df in df_list:\n",
    "        grouped_dfs[len(df.columns)].append(df)\n",
    "\n",
    "    # List to hold merged DataFrames\n",
    "    merged_dfs = []\n",
    "\n",
    "    # Merge DataFrames in each group\n",
    "    for key in grouped_dfs:\n",
    "        # Use the column names from the first DataFrame in the group for all DataFrames\n",
    "        standard_columns = grouped_dfs[key][0].columns\n",
    "        adjusted_dfs = []\n",
    "\n",
    "        for df in grouped_dfs[key]:\n",
    "            df_new = df.copy()\n",
    "            df_new.columns = standard_columns\n",
    "\n",
    "            # Append the adjusted DataFrame to the list\n",
    "            adjusted_dfs.append(df_new)\n",
    "\n",
    "        # Concatenate DataFrames in the same group\n",
    "        merged_df = pd.concat(adjusted_dfs, ignore_index=True)\n",
    "        merged_dfs.append(merged_df)\n",
    "\n",
    "    return merged_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_headers(table, col_count, table_index):\n",
    "    col_headers = []\n",
    "    cells = table.get('cells')\n",
    "    if table_index == 0:\n",
    "        for i in range(col_count):\n",
    "            col_cells = [cell for cell in cells if cell.get(\n",
    "                'column_index') == i and cell.get('kind') == 'columnHeader']\n",
    "            if col_cells:\n",
    "                max_row_in_column = max([cell.get('row_index')\n",
    "                                        for cell in col_cells])\n",
    "                for cell in col_cells:\n",
    "                    if cell.get('row_index') == max_row_in_column:\n",
    "                        header_content = cell.get('content')\n",
    "                        if header_content == '':\n",
    "                            col_headers.append(f\"Unnamed: {i}\")\n",
    "                        else:\n",
    "                            col_headers.append(cell.get('content'))\n",
    "            else:\n",
    "                col_headers.append(f\"Unnamed: {i}\")\n",
    "    else:\n",
    "        for i in range(col_count):\n",
    "            col_headers.append(f\"Unnamed: {i}\")\n",
    "    return col_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_data(table):\n",
    "    table_data = []\n",
    "    cells = table.get('cells')\n",
    "    for row in range(table.get('row_count')):\n",
    "        row_content = []\n",
    "        for col in range(table.get('column_count')):\n",
    "            cell = next((cell for cell in cells if cell.get(\n",
    "                'row_index') == row and cell.get('column_index') == col), None)\n",
    "            if cell and cell.get('kind') == 'content':\n",
    "                row_content.append(cell.get('content'))\n",
    "            else:\n",
    "                row_content.append(None)\n",
    "        # Check if all values in the row are None\n",
    "        if not all(value is None for value in row_content):\n",
    "            table_data.append(row_content)\n",
    "    return table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to append text to a file\n",
    "def append_text_to_file(filename, text):\n",
    "    # Open the file in append mode ('a') and text mode ('t'), hence 'at'\n",
    "    with open(filename, 'at') as file:\n",
    "        # Write the text followed by a newline character\n",
    "        file.write(text + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def clean_df(df):\n",
    "    # Step 1: Replace \":unselected:\" and \":selected:\" with an empty string\n",
    "    df.replace(to_replace=r\":unselected:|:selected:\", value=\"\", regex=True, inplace=True)\n",
    "    \n",
    "    # Step 2: Extract last word if spaces are present, then remove non-alphanumeric characters\n",
    "    def clean_cell(x):\n",
    "        if isinstance(x, str):\n",
    "            # Check if there are spaces and take the last part\n",
    "            parts = x.strip().split()\n",
    "            last_part = parts[-1] if parts else \"\"\n",
    "            # Remove non-alphanumeric characters from the last part\n",
    "            return re.sub(r'[^a-zA-Z0-9]', '', last_part)\n",
    "        return x\n",
    "\n",
    "    # Apply the cleaning function to each cell in the DataFrame\n",
    "    cleaned_df = df.applymap(clean_cell)\n",
    "    \n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def final_run():\n",
    "    json_dir = 'results/Parsed_Pdfs/Chhattisgarh/AE_2018'\n",
    "    # json_dir = 'results/Parsed_Pdfs/Maharastra/Assembly Election 2019/JSON_Maharastra_2019_AC_230.json'\n",
    "    # output_dir = 'Parsed_Pdfs/Maharastra/Assembly Election 2019/Excel_Files'\n",
    "    # os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    log_file_name = \"llogs/CH_json_to_excel_AE_2018.txt\"\n",
    "\n",
    "    for filename in os.listdir(json_dir):\n",
    "        if filename.endswith('.json'):\n",
    "            # if filename.endswith('AC_038.json'):\n",
    "\n",
    "            with open(os.path.join(json_dir, filename)) as f:\n",
    "                data = json.load(f)\n",
    "            try:\n",
    "                tables = data['tables']\n",
    "\n",
    "                tables_df = []\n",
    "                for table_index, table in enumerate(tables):\n",
    "                    table_data = get_table_data(table)\n",
    "                    initial_df = pd.DataFrame(table_data)\n",
    "                    current_headers = get_column_headers(\n",
    "                        table, col_count=initial_df.shape[1], table_index=table_index)\n",
    "                    # col_count = table.get('column_count', len(current_headers))\n",
    "                    # if len(current_headers) < col_count:\n",
    "                    #     current_headers.extend([f\"Unnamed: {i}\" for i in range(len(current_headers), col_count)])\n",
    "                    # elif len(current_headers) > col_count:\n",
    "                    #     current_headers = current_headers[:col_count]\n",
    "                    df = pd.DataFrame(table_data, columns=current_headers)\n",
    "\n",
    "                    # # Construct output filename and path\n",
    "                    # output_filename = f\"table_{table_index + 1}_from_{filename.replace('.json', '')}.xlsx\"\n",
    "                    # output_filepath = os.path.join(output_dir, output_filename)\n",
    "\n",
    "                    # # df.replace({\":unselected:\": \"\", \":selected:\": \"\"}, inplace=True)\n",
    "                    # with pd.ExcelWriter(output_filepath, engine='xlsxwriter') as writer:\n",
    "                    #     df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "                    tables_df.append(df)\n",
    "\n",
    "                if len(tables_df) > 0:\n",
    "                    merged_dfs = concatenate_dfs(tables_df)\n",
    "                else:\n",
    "                    print(f\"No tables found in {filename}\")\n",
    "                    continue\n",
    "\n",
    "                # excel_files = load_excel_files(output_dir)\n",
    "                # if len(excel_files) < 2:\n",
    "                #     print(\"There are not enough Excel files to combine.\")\n",
    "                #     return\n",
    "\n",
    "                folder_path = 'results/Parsed_Excel/Chhattisgarh/AE_2018'\n",
    "                os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "                output_file = os.path.join(\n",
    "                    folder_path, f\"combined_{filename}.xlsx\")\n",
    "                with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "\n",
    "                    for index, df in enumerate(merged_dfs):\n",
    "                        sheet_name = f'Sheet_{index+1}'\n",
    "\n",
    "                        cleaned_df = clean_df(df)\n",
    "\n",
    "                        cleaned_df.to_excel(\n",
    "                            writer, index=False, sheet_name=sheet_name)\n",
    "\n",
    "                print(\"Excel files combined and saved successfully.\")\n",
    "            except Exception as exc:\n",
    "                print(f\"Error processing {filename}: {exc}\")\n",
    "                append_text_to_file(log_file_name, f\"{filename} \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39992/3352595160.py:19: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  cleaned_df = df.applymap(clean_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n",
      "Excel files combined and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "final_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def final_run():\n",
    "#     # json_dir = 'results/Parsed_Pdfs/Maharastra/'\n",
    "#     json_dir = 'results/Parsed_Pdfs/Maharastra/Assembly Election 2019/'\n",
    "#     # output_dir = 'Parsed_Pdfs/Maharastra/Assembly Election 2019/Excel_Files'\n",
    "#     # os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "#     log_file_name = \"logs/maharastra_2019_excelfile_log.txt\"\n",
    "\n",
    "#     for filename in os.listdir(json_dir):\n",
    "#         if filename.endswith('.json'):\n",
    "#             # if filename.endswith('AC_038.json'):\n",
    "\n",
    "#             with open(os.path.join(json_dir, filename)) as f:\n",
    "#                 data = json.load(f)\n",
    "#             try:\n",
    "#                 tables = data['tables']\n",
    "\n",
    "#                 tables_df = []\n",
    "#                 for table_index, table in enumerate(tables):\n",
    "#                     table_data = get_table_data(table)\n",
    "#                     initial_df = pd.DataFrame(table_data)\n",
    "#                     current_headers = get_column_headers(\n",
    "#                         table, col_count=initial_df.shape[1], table_index=table_index)\n",
    "#                     # col_count = table.get('column_count', len(current_headers))\n",
    "#                     # if len(current_headers) < col_count:\n",
    "#                     #     current_headers.extend([f\"Unnamed: {i}\" for i in range(len(current_headers), col_count)])\n",
    "#                     # elif len(current_headers) > col_count:\n",
    "#                     #     current_headers = current_headers[:col_count]\n",
    "#                     df = pd.DataFrame(table_data, columns=current_headers)\n",
    "\n",
    "#                     # # Construct output filename and path\n",
    "#                     # output_filename = f\"table_{table_index + 1}_from_{filename.replace('.json', '')}.xlsx\"\n",
    "#                     # output_filepath = os.path.join(output_dir, output_filename)\n",
    "\n",
    "#                     # # df.replace({\":unselected:\": \"\", \":selected:\": \"\"}, inplace=True)\n",
    "#                     # with pd.ExcelWriter(output_filepath, engine='xlsxwriter') as writer:\n",
    "#                     #     df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "#                     tables_df.append(df)\n",
    "\n",
    "#                 if len(tables_df) > 0:\n",
    "#                     merged_dfs = concatenate_dfs(tables_df)\n",
    "#                 else:\n",
    "#                     print(f\"No tables found in {filename}\")\n",
    "#                     continue\n",
    "\n",
    "#                 # excel_files = load_excel_files(output_dir)\n",
    "#                 # if len(excel_files) < 2:\n",
    "#                 #     print(\"There are not enough Excel files to combine.\")\n",
    "#                 #     return\n",
    "\n",
    "#                 folder_path = 'results/Parsed_Excel/Rajasthan/2018'\n",
    "#                 os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "#                 output_file = os.path.join(\n",
    "#                     folder_path, f\"combined_{filename}.xlsx\")\n",
    "#                 with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "\n",
    "#                     for index, df in enumerate(merged_dfs):\n",
    "#                         sheet_name = f'Sheet_{index+1}'\n",
    "\n",
    "#                         cleaned_df = clean_df(df)\n",
    "\n",
    "#                         cleaned_df.to_excel(\n",
    "#                             writer, index=False, sheet_name=sheet_name)\n",
    "\n",
    "#                 print(\"Excel files combined and saved successfully.\")\n",
    "#             except Exception as exc:\n",
    "#                 print(f\"Error processing {filename}: {exc}\")\n",
    "#                 append_text_to_file(log_file_name, f\"{filename} \\n\")\n",
    "\n",
    "# final_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for the excel files have rowcount ress than 10\n",
    "\n",
    "# import logging\n",
    "# import os\n",
    "\n",
    "# # Define the folder path containing the Excel files\n",
    "# folder_path = 'results/Parsed_Excel/Maharastra/Assembly Election 2019'\n",
    "# log_file_name = \"logs/maharstra_excelfile_log_for_rowcount.txt\"\n",
    "# logging.basicConfig(filename=log_file_name, level=logging.ERROR,\n",
    "#                     format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# # Get a list of all files in the folder\n",
    "# files = os.listdir(folder_path)\n",
    "\n",
    "\n",
    "# for file in files:\n",
    "#     if file.endswith('.xlsx') or file.endswith('.xls'):\n",
    "#         file_path = os.path.join(folder_path, file)\n",
    "#         df = pd.read_excel(file_path)\n",
    "#         num_rows = df.shape[0]\n",
    "#         if num_rows < 75:\n",
    "#             logging.error(\n",
    "#                 f\"File '{file}' has less than 75 rows ({num_rows} rows).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
